#In this project we will classify 'T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Boot',
#'Ankle boot'.

#importing libraries

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
from keras.layers.core import Dropout, Activation, Dense, Flatten
from keras.models import Sequential
from sklearn.metrics import accuracy_score


(x_train, y_train), (x_test,y_test) = datasets.fashion_mnist.load_data()

#to see shape of the data 
# x_train.shape, x_test.shape, y_train.shape, y_test.shape

#reshaping the data to single dimension
x_train_reshaped = x_train.reshape(60000, 784)
x_test_reshaped = x_test.reshape(10000, 784)

#to get RGB pixel value in range from 0 to 1 let divide them by 255
x_train = x_train/255
x_test = x_test/255

#lets plot the visualzation of an x_train_reshaped after it gets reshaped from pixel range from 0 to 255
#here below chart gives number of pixels with that given range from 0 to 255
plt.hist(x_train_reshaped[0])

#lets plot image
plt.imshow(x_train[0])

#dividing into classes
classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Boot', 'Ankle boot']
#if we print y_train[0], we will get 9 and if we plot it we will get the image of ankle boot. so here Ankle boot = 9 and
#i.e T- shirt = 0, Trouser = 1 and so on...


#using train test split, lets split the data to make the data size under 10000, to make our fresh x_train, x_test etc
#here x_test size is 10000 lets make it under 1000 , (here x_test size is 10000, inorder to make it under 1000 see below code)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_test, y_test, test_size = 0.9001, random_state = 42)

#checking train size and test size, here you can see our x_train is under 1000 i.e 999 
print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)


#Building the model
model = Sequential()
model.add(Flatten(input_shape = (28,28)))
model.add(Dense(150))
model.add(Activation('relu'))
model.add(Dense(50))
model.add(Activation('relu'))

model.add(Dense(10))
model.add(Activation('softmax'))

model.compile(loss = "sparse_categorical_crossentropy", optimizer='adam', metrics=['accuracy'])

#fitting model
model.fit(x_train,y_train, epochs=10)

#making predictions
y_predict = model.predict(x_test)
y_predicted = [np.argmax(element) for element in y_predict]

len(y_predicted)
len(y_test)

#you can see i have predicted over 9000 images with just 999 training dataset
 
#now calculating accuracy, lets check accuracy results on remaining 9000 data in x_test inintially......
k = accuracy_score(y_predicted,y_test)
print(k)

# if you have any doubts regarding this.. you can contact me......                         sivasaineeli.ss@gmail.com

